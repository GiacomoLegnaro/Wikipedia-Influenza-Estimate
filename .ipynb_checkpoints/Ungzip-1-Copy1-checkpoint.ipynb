{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "import cleanfile\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    \"Influenza\",\n",
    "    \"Febbre\",\n",
    "    \"Rinorrea\",\n",
    "    \"Mialgia\",\n",
    "    \"Artralgia\",\n",
    "    \"Vaccino_antinfluenzale\",\n",
    "    \"Oseltamivir\",\n",
    "    \"Antivirale\",\n",
    "    \"Virus_dell'influenza_A_sottotipo_H1N1\",\n",
    "    \"Influenzavirus_A_sottotipo_H1N1\",\n",
    "    \"Paracetamolo\",\n",
    "    \"Influenzavirus_A\",\n",
    "    \"Cefalea\",\n",
    "    \"Tosse\",\n",
    "    \"Pandemia_influenzale\",\n",
    "    \"Starnuto\",\n",
    "    \"Fotofobia\",\n",
    "    \"Zanamivir\",\n",
    "    \"Amantadina\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = [\"Vomito\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cStringIO\n",
    "import gzip\n",
    "import subprocess\n",
    "import time\n",
    "from itertools import islice\n",
    "\n",
    "io_method = cStringIO.StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_FILE = '/Volumes/My Book/Wikimedia/pagecounts-raw/2016'\n",
    "FILE_DIR = '/Users/giacomolegnaro/Documents/Data Science/2nd Year/Digital Epidemiology/Homework2/Wikimedia/clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dirname, dirnames, filenames in os.walk(PATH_TO_FILE):\n",
    "    for subdirname in dirnames:\n",
    "        print subdirname\n",
    "        for gzip_path in glob.glob(os.path.join(dirname, subdirname) + \"/*.gz\"):\n",
    "            fileName = gzip_path.split('/')[-1][:-3].split('-')\n",
    "            print gzip_path.split('/')[-1][:-3]\n",
    "            # dt = datetime.datetime.strptime(fileName,'%Y%m%d%H%M%S')\n",
    "            if os.path.isdir(gzip_path) == False:\n",
    "                p = subprocess.Popen(['gzcat', gzip_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "                fh = io_method(p.communicate()[0])\n",
    "                assert p.returncode == 0\n",
    "                ct = 0\n",
    "                for line in islice(fh, 3500000, None):\n",
    "                    lineList = line.split(' ')\n",
    "                    if lineList[0] == 'it':\n",
    "                        try:\n",
    "                            ct += int(lineList[2])\n",
    "                        except IndexError:\n",
    "                            ct += 0\n",
    "                        if lineList[1] in keywords:\n",
    "                            with open(FILE_DIR + '/' + lineList[1] + '.txt', 'a') as output:\n",
    "                                output.write(fileName[1] + fileName[2] + ' ' + lineList[2] + '\\n')\n",
    "                    elif ((lineList[0] != 'it') and (ct != 0)):\n",
    "                        break\n",
    "                \n",
    "                with open (FILE_DIR + '/' 'totalViews.txt','a') as output:\n",
    "                    output.write(fileName[1] + fileName[2] + ' ' + str(ct) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_FILE = '/Volumes/My Book/Wikimedia/pageviews/2016'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_FILE = '/Volumes/My Book/Wikimedia/pagecounts-raw/2012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01\n",
      "pageviews-20160101-000000\n",
      "pageviews-20160101-010000\n",
      "pageviews-20160101-020000\n",
      "pageviews-20160101-030000\n",
      "pageviews-20160101-040000\n",
      "pageviews-20160101-050000\n",
      "pageviews-20160101-060000\n",
      "pageviews-20160101-070000\n",
      "pageviews-20160101-080000\n",
      "pageviews-20160101-090000\n",
      "pageviews-20160101-100000\n",
      "pageviews-20160101-110000\n",
      "pageviews-20160101-120000\n",
      "pageviews-20160101-130000\n",
      "pageviews-20160101-140000\n",
      "pageviews-20160101-150000\n",
      "pageviews-20160101-160000\n",
      "pageviews-20160101-170000\n",
      "pageviews-20160101-180000\n",
      "pageviews-20160101-190000\n",
      "pageviews-20160101-200000\n",
      "pageviews-20160101-210000\n"
     ]
    }
   ],
   "source": [
    "for dirname, dirnames, filenames in os.walk(PATH_TO_FILE):\n",
    "    for subdirname in dirnames:\n",
    "        print subdirname\n",
    "        for gzip_path in glob.glob(os.path.join(dirname, subdirname) + \"/*.gz\"):\n",
    "            fileName = gzip_path.split('/')[-1][:-3].split('-')\n",
    "            print gzip_path.split('/')[-1][:-3]\n",
    "            # dt = datetime.datetime.strptime(fileName,'%Y%m%d%H%M%S')\n",
    "            if os.path.isdir(gzip_path) == False:\n",
    "                p = subprocess.Popen(['gzcat', gzip_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "                fh = io_method(p.communicate()[0])\n",
    "                assert p.returncode == 0\n",
    "                ct = 0\n",
    "                for line in islice(fh, 3500000, None):\n",
    "                    lineList = line.split(' ')\n",
    "                    if lineList[0] == 'it':\n",
    "                        if lineList[1] in keywords:\n",
    "                            with open(FILE_DIR + '/' + lineList[1] + '.txt', 'a') as output:\n",
    "                                output.write(fileName[1] + fileName[2] + ' ' + lineList[2] + '\\n')\n",
    "                    elif ((lineList[0] != 'it') and (ct != 0)):\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gzipstream import GzipStreamFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'https://dumps.wikimedia.org/other/pageviews/2016/2016-03/pageviews-20160301-000000.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b96bc3bfd424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://dumps.wikimedia.org/other/pageviews/2016/2016-03/pageviews-20160301-000000.gz'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Any streaming file object that supports `read`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipStreamFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'https://dumps.wikimedia.org/other/pageviews/2016/2016-03/pageviews-20160301-000000.gz'"
     ]
    }
   ],
   "source": [
    "f = open('https://dumps.wikimedia.org/other/pageviews/2016/2016-03/pageviews-20160301-000000.gz') # Any streaming file object that supports `read`\n",
    "gz = GzipStreamFile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Provato solo l'import di una timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c=pd.Series.from_csv('/Volumes/My Book/Wikimedia/clean/Antivirale.txt', sep = ' ', header=None, index_col = 0, parse_dates=True, infer_datetime_format=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = [str(d.isocalendar()[0])+'-'+str(d.strftime(\"%V\"))  for d in c.index.date]\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codice Sporco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for dirname, dirnames, filenames in os.walk(PATH_TO_FILE):\n",
    "    print dirname\n",
    "    print dirnames\n",
    "    #print filenames\n",
    "    # print path to all subdirectories first.\n",
    "    for subdirname in dirnames:\n",
    "        for gzip_path in glob.glob(os.path.join(dirname, subdirname) + \"/*.gz\"):\n",
    "            print gzip_path.split('/')[-1][:-3].split('-')\n",
    "            fileName = gzip_path.split('/')[-1][:-3].split('-')\n",
    "            # dt = datetime.datetime.strptime(fileName,'%Y%m%d%H%M%S')\n",
    "            if os.path.isdir(gzip_path) == False:\n",
    "                data = pd.read_csv(gzip_path, header=None, names=['project_name', 'title', 'requests', 'size'], compression ='gzip', sep=' ')\n",
    "                it = data[data[['project_name']].values=='it']\n",
    "                with open(FILE_DIR + '/' 'totalViews.txt','a') as output:\n",
    "                    output.write(fileName[1] + fileName[2] + ' '\n",
    "                                 + str(sum(it['requests'])) +'\\n')\n",
    "                for k in keywords:\n",
    "                    try:\n",
    "                        r = int(it[it[['title']].values==k]['requests'].values)\n",
    "                    except TypeError :\n",
    "                        r = 0\n",
    "                    with open(FILE_DIR + '/' + k + '.txt', 'a') as output:\n",
    "                            output.write(fileName[1] + fileName[2] + ' ' + str(r) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
